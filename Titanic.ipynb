{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Introduction to Apache Spark lab, Lab 3: Binary Classification with Spark ML\n\n### In this notebook, we will explore Binary Classification using Spark ML. We will exploit Spark ML's high-level APIs built on top of DataFrames to create and tune machine learning pipelines. Spark ML Pipelines enable combining multiple algorithms into a single pipeline or workflow. We will heavily utilize Spark ML's feature transformers to convert, modify and scale the features that will be used to develop the machine learning model. Finally, we will evaluate and cross validate our model to demonstrate the process of determining a best fit model.\n\n### The binary classification demo will utilize the famous Titanic dataset, which has been used for Kaggle competitions and can be downloaded here. There is no need to download the data manually as it is downloaded directly within the noteboook.\nhttps://www.kaggle.com/c/titanic/data\n\n\n### The Titanic data set was chosen for this binary classification demonstration because it contains both text based and numeric features that are both continuous and categorical. This will give us the opportunity to explore and utilize a number of feature transformers available in Spark ML.\n     \n          \n\n![IBM Logo](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSzlUYaJ9xykGC-N5PijcV_eDBGCXy_pMn7sy6ymrVypmJ22q5ZmA)", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Table of contents\n\n1. [Install needed libraries](#libraries)<br/>\n2. [Get the Data](#getdata)<br/>\n3. [Prepare and clean the data](#prepare)<br/>\n    3.1 [Remove unneeded columns](#remove)<br/>\n4. [Transform the data](#transform)<br/>\n    4.1 [Gender and Embarkation](#stringindexer)<br/>\n    4.2 [Age and Fare](#bucketizer)<br/>\n5. [Build the Model](#build)<br/>\n6. [Split the data into train and test sets](#split)<br/>\n7. [Test the Model](#test)<br/>\n8. [Save the Model](#save)<br>\n9. [Tune the Model](#tune)<br/>\n10. [Predict imaginary passenger](#predict)<br/>\n11. [Random Forest](#randomforest)<br/>\n12. [Summary](#summary)<br/>", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Verify Spark version and existence of Spark and Spark SQL contexts", 
            "cell_type": "markdown"
        }, 
        {
            "source": "print ( spark.version)\n\n", 
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "2.1.2\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"libraries\"></a>\n## 1 - Import required Spark libraries ", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "#### After executing this block, you should see a message saying that the `Pixiedust database opened successfully`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import Bucketizer\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n#import pixiedust display module\nfrom pixiedust.display import *", 
            "metadata": {}, 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Pixiedust database opened successfully\n"
                }, 
                {
                    "data": {
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.6</span>\n        </div>\n        ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}, 
                    "output_type": "display_data"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"getdata\"></a>\n## 2 - Download Data", 
            "cell_type": "markdown"
        }, 
        {
            "source": "!rm -f Titanic.csv\n!wget https://ibm.box.com/shared/static/crceca9g1ym3nl0hwaxa5c0j0m3e19l8.csv -O Titanic.csv -q\n!ls -l Titanic.csv\n\n", 
            "metadata": {}, 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "-rw------- 1 se77-d3e315d6b90387-53b8b920f77e users 61194 Jan 29 20:38 Titanic.csv\r\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "### Read data in as a DataFrame\n### Source data is in CSV format and includes a header. We will ask Spark to infer the schema/data types.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "\nloadTitanicData = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"Titanic.csv\")\n", 
            "metadata": {}, 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"prepare\"></a>\n## 3. Prepare and shape the data\n\nPixieDust is an open-source IBM library which can be used to easily and flexibly `display` data.\n\nUse PixieDust to examine the schema (click on the Schema line).   Try differing displays of the data using PixieDust.\n\nFor example, try showing a histogram of `fare` or `age` or `pclass`.    Change the renderer and see what happens.\n<br>\n\n</div> ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "display(loadTitanicData)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "rendererId": "seaborn", 
                        "clusterby": "Survived", 
                        "charttype": "stacked", 
                        "keyFields": "Pclass", 
                        "aggregation": "SUM", 
                        "rowCount": "500", 
                        "handlerId": "barChart"
                    }
                }
            }, 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFiguredf0694d2\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                    \n                            <center><img style=\"max-width:initial !important\" src=\"data:image/png;base64,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\" class=\"pd_save\"></center>\n                        \n                    \n                \n        </div>\n    ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}, 
                    "output_type": "display_data"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"remove\"></a>\n## 3.1 - Drop unwanted columns and rows with null or invalid data.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# drop PassengerID, Name, Ticket and Cabin columns.   drop any rows where Age or Embarked columns have no data\n\nloadTitanicData = loadTitanicData.drop(\"PassengerId\").drop(\"Name\").drop(\"Ticket\").drop(\"Cabin\").dropna(how=\"any\", subset=(\"Age\", \"Embarked\"))\n", 
            "metadata": {}, 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "##  We will use the 'Survived' column as a label for training the machine learning model\n#### Spark ML requires that that the labels are data type Double, so we will cast the  column as Double (it was inferred as Integer when read into Spark).", 
            "cell_type": "markdown"
        }, 
        {
            "source": "LabeledTitanicData = (loadTitanicData.withColumn(\"SurvivedTemp\", loadTitanicData[\"Survived\"]\n    .cast(\"Double\")).drop(\"Survived\")\n    .withColumnRenamed(\"SurvivedTemp\", \"Survived\"))\nLabeledTitanicData.show(10)", 
            "metadata": {}, 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+------+----+-----+-----+-------+--------+--------+\n|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Survived|\n+------+------+----+-----+-----+-------+--------+--------+\n|     3|  male|22.0|    1|    0|   7.25|       S|     0.0|\n|     1|female|38.0|    1|    0|71.2833|       C|     1.0|\n|     3|female|26.0|    0|    0|  7.925|       S|     1.0|\n|     1|female|35.0|    1|    0|   53.1|       S|     1.0|\n|     3|  male|35.0|    0|    0|   8.05|       S|     0.0|\n|     1|  male|54.0|    0|    0|51.8625|       S|     0.0|\n|     3|  male| 2.0|    3|    1| 21.075|       S|     0.0|\n|     3|female|27.0|    0|    2|11.1333|       S|     1.0|\n|     2|female|14.0|    1|    0|30.0708|       C|     1.0|\n|     3|female| 4.0|    1|    1|   16.7|       S|     1.0|\n+------+------+----+-----+-----+-------+--------+--------+\nonly showing top 10 rows\n\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "## Print some record counts", 
            "cell_type": "markdown"
        }, 
        {
            "source": "print('The total number of rows is {}.'.format(LabeledTitanicData.count()))\nprint('The number of rows labeled Not Survived is {}.'.format(LabeledTitanicData.filter(LabeledTitanicData['Survived'] == 0).count()))\nprint('The number of rows labeled Survived is {}.'.format(LabeledTitanicData.filter(LabeledTitanicData['Survived'] == 1).count()))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"transform\"></a>\n## 4. Transform the data\n\nCertain data fields need to be transformed before building the model.   This can be for several reasons ranging from needing to convert String values to numeric values or shaping data into different formats.\n\n<a id=\"stringindexer\"></a>\n## 4.1 Use <a href=\"https://spark.apache.org/docs/latest/ml-features.html#stringindexer\">StringIndexer</a> to transform gender and embarked values\n\nStringIndexer is a transformer that encodes a string column to a column of indices. The indices are ordered by value frequencies, so the most frequent value gets index 0. If the input column is numeric, it is cast to string first. \n\nFor the Titanic data set, we will index the Sex/Gender column as well as the Embarked column, which specifies at which  port the passenger boarded the ship.## StringIndexer", 
            "cell_type": "markdown"
        }, 
        {
            "source": "SexIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\nEmbarkedIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")", 
            "metadata": {}, 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"bucketizer\"></a>\n## 4.2 <a href=\"https://spark.apache.org/docs/latest/ml-features.html#bucketizer\">Bucketizer</a> is a transformer that transforms a column of continuous features to a column of feature buckets, where the buckets are by a splits parameter. \n\nFor the Titanic data set, we will index the Age and Fare features.\n\n<br/>\n", 
            "cell_type": "markdown"
        }, 
        {
            "source": "AgeBucketSplits = [0.0, 6.0, 12.0, 18.0, 40.0, 65.0, 80.0, float(\"inf\")]\nAgeBucket = Bucketizer(splits=AgeBucketSplits, inputCol=\"Age\", outputCol=\"AgeBucket\")\n\nFareBucketSplits = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 80.0, 100.0, float(\"inf\")]\nFareBucket = Bucketizer(splits=FareBucketSplits, inputCol=\"Fare\", outputCol=\"FareBucket\")", 
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"build\"></a>\n## 5. Building the Model\n\n## <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> is a transformer that combines a given list of columns in the order specified into a single vector column in order to train a model.\n\n<br/>\n", 
            "cell_type": "markdown"
        }, 
        {
            "source": "assembler = VectorAssembler(inputCols= [\"SexIndex\", \"EmbarkedIndex\", \"AgeBucket\", \"FareBucket\", \"SibSp\", \"Pclass\", \"Parch\"], outputCol=\"features\")", 
            "metadata": {}, 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Normalizer is a Transformer which transforms a dataset of Vector rows, normalizing each Vector to have unit norm\n### This normalization can help standardize your input data and improve the behavior of learning algorithms.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)", 
            "metadata": {}, 
            "execution_count": 11, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Logistic regression is a popular method to predict a binary response\n### It is a special case of Generalized Linear models that predicts the probability of an outcome.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "lr = LogisticRegression(featuresCol=\"normFeatures\", labelCol=\"Survived\", predictionCol=\"prediction\", maxIter=10, regParam=0.1, elasticNetParam=0.8)", 
            "metadata": {}, 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## A Pipeline is a sequence of stages where each stage is either a Transformer or an Estimator\n### These stages are run in order and the input DataFrame is transformed as it passes through each stage. \n\n### In machine learning, it is common to run a sequence of algorithms to process and learn from data.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "pipeline = Pipeline(stages=[SexIndexer, EmbarkedIndexer, AgeBucket,FareBucket, assembler, normalizer, lr])", 
            "metadata": {}, 
            "execution_count": 13, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"split\"></a>\n## 6 - Split the data into training (70%) and testing (30%) sets using <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit\">random_split()</a>\n\nSet seed to 1 in order to make certain this is repeatable.\n<br>\n \n</div> ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "train, test = LabeledTitanicData.randomSplit([70.0,30.0], seed=1)\ntrain.cache()\ntest.cache()\nprint('The number of records in the traininig data set is {}.'.format(train.count()))\nprint('The number of rows labeled Not Survived in the training data set is {}.'.format(train.filter(train['Survived'] == 0).count()))\nprint('The number of rows labeled Survived in the training data set is {}.'.format(train.filter(train['Survived'] == 1).count()))\ntrain.sample(False, 0.01, seed=0).show(5)\nprint('')\n\nprint('The number of records in the test data set is {}.'.format(test.count()))\nprint('The number of rows labeled Not Survived in the test data set is {}.'.format(test.filter(train['Survived'] == 0).count()))\nprint('The number of rows labeled Survived in the test data set is {}.'.format(test.filter(train['Survived'] == 1).count()))\ntest.sample(False, 0.1, seed=0).show(5)\n", 
            "metadata": {}, 
            "execution_count": 14, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "The number of records in the traininig data set is 497.\nThe number of rows labeled Not Survived in the training data set is 281.\nThe number of rows labeled Survived in the training data set is 216.\n+------+----+----+-----+-----+-------+--------+--------+\n|Pclass| Sex| Age|SibSp|Parch|   Fare|Embarked|Survived|\n+------+----+----+-----+-----+-------+--------+--------+\n|     1|male|48.0|    1|    0|76.7292|       C|     1.0|\n|     3|male|18.0|    1|    1|20.2125|       S|     0.0|\n|     3|male|30.0|    0|    0| 7.2292|       C|     0.0|\n+------+----+----+-----+-----+-------+--------+--------+\n\n\nThe number of records in the test data set is 215.\nThe number of rows labeled Not Survived in the test data set is 143.\nThe number of rows labeled Survived in the test data set is 72.\n+------+----+----+-----+-----+--------+--------+--------+\n|Pclass| Sex| Age|SibSp|Parch|    Fare|Embarked|Survived|\n+------+----+----+-----+-----+--------+--------+--------+\n|     1|male|24.0|    0|    1|247.5208|       C|     0.0|\n|     1|male|36.0|    1|    2|   120.0|       S|     1.0|\n|     1|male|45.0|    1|    0|  83.475|       S|     0.0|\n|     1|male|49.0|    1|    0| 56.9292|       C|     1.0|\n|     1|male|62.0|    0|    0|   26.55|       S|     0.0|\n+------+----+----+-----+-----+--------+--------+--------+\nonly showing top 5 rows\n\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "## Fit the pipeline to the training data", 
            "cell_type": "markdown"
        }, 
        {
            "source": "model = pipeline.fit(train)", 
            "metadata": {}, 
            "execution_count": 15, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"test\"></a>\n## 7 - Make predictions on passengers in the Test data set\n### Keep in mind that the model has not seen the data in the test data set", 
            "cell_type": "markdown"
        }, 
        {
            "source": "predictions = model.transform(test)", 
            "metadata": {}, 
            "execution_count": 16, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Show results", 
            "cell_type": "markdown"
        }, 
        {
            "source": "predictions.sample(False, 0.2, seed=0).select(\"Sex\",\"Pclass\",\"Survived\",\"Prediction\").show(10)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "print('The number of predictions labeled Not Survived is {}.'.format(predictions.filter(predictions['prediction'] == 0).count()))\nprint('The number of predictions labeled Survived is {}.'.format(predictions.filter(predictions['prediction'] == 1).count()))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "(predictions.filter(\"Survived = 0.0\")\n     .select(\"Sex\", \"Age\", \"Fare\", \"Embarked\", \"Pclass\", \"Parch\", \"SibSp\", \"Survived\", \"prediction\")\n     .sample(False, 0.2, seed=0).show(10))\n\n(predictions.filter(\"Survived = 1.0\")\n     .select(\"Sex\", \"Age\", \"Fare\", \"Embarked\", \"Pclass\", \"Parch\", \"SibSp\", \"Survived\", \"prediction\")\n     .sample(False, 0.5, seed=0).show(10))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "## Create an evaluator for the binary classification using area under the ROC Curve as the evaluation metric\n\n### Receiver operating characteristic (ROC) is a graphical plot that illustrates the performance of a binary classifier system as its discrimination threshold is varied\n\nThe curve is created by plotting the true positive rate against the false positive rate at various threshold settings. The ROC curve is thus the sensitivity as a function of fall-out. The area under the ROC curve is useful for comparing and selecting the best machine learning model for a given data set. A model with an area under the ROC curve score near 1 has very good performance. A model with a score near 0.5 is about as good as flipping a coin.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "evaluator = BinaryClassificationEvaluator().setLabelCol(\"Survived\").setMetricName(\"areaUnderROC\")\nprint('Area under the ROC curve = {}.'.format(evaluator.evaluate(predictions)))", 
            "metadata": {}, 
            "execution_count": 17, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Area under the ROC curve = 0.842997280497.\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"save\"></a>\n## 8 - Save Model\n### Persist Model to the Watson Machine Learning service. \n\n", 
            "cell_type": "markdown"
        }, 
        {
            "source": "#!pip install watson-machine-learning-client --upgrade", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "#from watson_machine_learning_client import WatsonMachineLearningAPIClient\nfrom repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact", 
            "metadata": {}, 
            "execution_count": 18, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {}, 
            "execution_count": 19, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "#client = WatsonMachineLearningAPIClient(wml_credentials)\nml_repository_client = MLRepositoryClient(wml_credentials['url'])\nml_repository_client.authorize(wml_credentials['username'], wml_credentials['password'])\n", 
            "metadata": {}, 
            "execution_count": 20, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "#model_props = {\"authorName\":\"IBM\", \"authorEmail\":\"beekmanb@us.ibm.com\"}\n#published_model = client.repository.store_model(model, \"Titanic Another Prediction model\", meta_props=model_props, training_data=train)\nmodel_artifact = MLRepositoryArtifact(model, training_data=train, name=\"Titanic Prediction v1\")\nsaved_model = ml_repository_client.models.save(model_artifact)", 
            "metadata": {}, 
            "execution_count": 21, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"tune\"></a>\n## 9 - Tune Hyperparameters\n### Generate hyperparameter combinations by taking the cross product of some parameter values\n\nSpark ML algorithms provide many hyperparameters for tuning models. These hyperparameters are distinct from the model parameters being optimized by Spark ML itself. Hyperparameter tuning is accomplished by choosing the best set of parameters based on model performance on test data that the model was not trained with. All combinations of hyperparameters specified will be tried in order to find the one that leads to the model with the best evaluation result.", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Build a Parameter Grid specifying what parameters and values will be evaluated in order to determine the best combination", 
            "cell_type": "markdown"
        }, 
        {
            "source": "paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.0, 0.1, 0.3])\n                 .addGrid(lr.elasticNetParam, [0.0, 0.8, 1.0])\n                 .addGrid(normalizer.p, [1.0, 2.0])\n                 .build())", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Create a cross validator to tune the pipeline with the generated parameter grid\nSpark ML provides for cross-validation for hyperparameter tuning. Cross-validation attempts to fit the underlying estimator with user-specified combinations of parameters, cross-evaluate the fitted models, and output the best one.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(10)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Cross-evaluate the ML Pipeline to find the best model\n### using the area under the ROC evaluator and hyperparameters specified in the parameter grid", 
            "cell_type": "markdown"
        }, 
        {
            "source": "cvModel = cv.fit(LabeledTitanicData)\nprint('Area under the ROC curve for best fitted model = {}.'.format(evaluator.evaluate(cvModel.transform(LabeledTitanicData))))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Let's see what improvement we achieve by tuning the hyperparameters using cross-evaluation ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "print('Area under the ROC curve for non-tuned model = {}.'.format(evaluator.evaluate(predictions)))\nprint('Area under the ROC curve for best fitted model = {}.'.format(evaluator.evaluate(cvModel.transform(LabeledTitanicData))))\nprint('Improvement = {0:0.2f}%'.format((evaluator.evaluate(cvModel.transform(LabeledTitanicData)) - evaluator.evaluate(predictions)) *100 / evaluator.evaluate(predictions)))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Make improved predictions using the Cross-validated model\n### Using the Test data set and DataFrame API", 
            "cell_type": "markdown"
        }, 
        {
            "source": "cvModel.transform(test).select(\"Survived\", \"prediction\").sample(False, 0.1, seed=0).show(10)", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "### Like above, but now using SQL", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# create temporary table\ncvModel.transform(test).createOrReplaceTempView(\"cvModelPredictions\")\nspark.sql(\"select Survived, prediction from cvModelPredictions\").sample(False, 0.1, seed=0).show(10)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"predict\"></a>\n## 10 - Make a prediction on an imaginary passenger", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Define the imaginary passenger's features", 
            "cell_type": "markdown"
        }, 
        {
            "source": "SexValue = 'female'\nAgeValue = 40.0\nFareValue = 15.0\nEmbarkedValue = 'C'\nPclassValue = 2\nSibSpValue = 1\nParchValue = 1\n\nPredictionFeatures = (spark.createDataFrame([(SexValue, AgeValue, FareValue, EmbarkedValue, PclassValue, SibSpValue, ParchValue)],\n    ['Sex', 'Age', 'Fare', 'Embarked', 'Pclass', 'SibSp', 'Parch']))\nPredictionFeatures.show()", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Predict whether the imaginary person would have survived\n### using the best fit model", 
            "cell_type": "markdown"
        }, 
        {
            "source": "SurvivedOrNotPrediction = cvModel.transform(PredictionFeatures)\nSurvivedOrNotPrediction.select('rawPrediction', 'probability', 'prediction').show(1, False)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Display Prediction Result", 
            "cell_type": "markdown"
        }, 
        {
            "source": "SurvivedOrNot = SurvivedOrNotPrediction.select(\"prediction\").first()[0]\nif SurvivedOrNot == 0.0:\n    print(\"Did NOT Survive\")\nelif(SurvivedOrNot == 1.0):\n    print(\"Did Survive!!!\")\nelse:\n    print(\"Invalid Prediction\")", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"randomforest\"></a>\n## 11 - Let's take a quick look at applying the feature engineering performed above to a Random Forest Model\n### Random forests are ensembles of decision trees. They combine many decision trees in order to reduce the risk of overfitting.\n### We won't do any hyperparamter tuning in this example, but just show how to create and evaluate the model using all default hyperparameters", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from pyspark.ml.classification import RandomForestClassificationModel, RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import IndexToString\n\n# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer().setInputCol(\"Survived\").setOutputCol(\"indexedLabel\").fit(LabeledTitanicData)\n\n# Train a RandomForest model\nrf = RandomForestClassifier().setLabelCol(\"indexedLabel\").setFeaturesCol(\"features\").setNumTrees(20)\n\n# Convert indexed labels back to original labels.\nlabelConverter = IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)\n\n# Create new Pipeline using the RandomForest model and all the same feature transformers used above for logistic regression\npipelineRF = Pipeline().setStages([labelIndexer, SexIndexer, EmbarkedIndexer, AgeBucket, FareBucket, assembler, normalizer, rf, labelConverter])\n\n# Train model.\nmodelRF = pipelineRF.fit(train)\n\n# Make predictions.\npredictionsRF = modelRF.transform(test)\n\n# Select example rows to display.\npredictionsRF.select(\"predictedLabel\", \"Survived\", \"features\").show(10)\n\n# Select (prediction, true label) and compute test error\nevaluatorRF = MulticlassClassificationEvaluator().setLabelCol(\"Survived\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\naccuracyRF = evaluatorRF.evaluate(predictionsRF)\nprint(\"Accuracy = %g\" % accuracyRF)\nprint(\"Test Error = %g\" % (1.0 - accuracyRF))\n\nrfModel = modelRF.stages[7]\nprint(rfModel)  # summary only", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "<a id=\"summary\"></a>\n![IBM Logo](http://www-03.ibm.com/press/img/Large_IBM_Logo_TN.jpg)\n\nYou created a predictive model that predicts survival probabilities for passengers on the Titanic.\n\n  - Load the data\n  - Cleaned the data\n  - Created transformers to shape the data\n  - Created a model using Pipeline\n  - Split the data into training and test sets\n  - Tested the model\n  - Tuned the model\n  - Tested the model on an imaginary passenger\n  - Build a second model using Random Forest\n  ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}